# Issue/Template Advice

## Which issue type should I use?

Use the template that best matches the size and intent of the work:

- [ğŸ—ºï¸ Epic](#epic)
- [ğŸ’¡ Feature](#feature)
- [ğŸ§© Task](#task)
- [ğŸ› Bug Report](#bug)
- [ğŸ” Pull Request (PR)](#pull_request)
- [ğŸ›Ÿ Support](#support)

---

<a id="epic"></a>
### ğŸ—ºï¸ Epic

Use an Epic for a **single, coherent outcome** that will take **multiple sprints** and will be delivered through multiple **Features** (which then break down into Tasks). An Epic should describe the *why*, the *scope boundaries*, and what â€œdoneâ€ looks like â€” itâ€™s not a general bucket for unrelated work.

#### Epic field examples

##### Outcome / goal
***What are we trying to achieve, for whom, and why now?***

Example:
- **Outcome:** Operators can start/stop key subsystems remotely and confirm execution without being onsite.
- **Stakeholders / users impacted:** Field operators, support engineers, on-call.
- **Why now:** Reduces site visits during winter deployments; current process is slow and error-prone.
- **How weâ€™ll measure success (optional):** 80% fewer â€œonsite requiredâ€ interventions for routine operations; mean time to recover from operator error reduced by 50%.

##### Scope
***High-level â€œin vs outâ€ boundaries so the Epic stays manageable.***

Example:
- **In scope:**
  - Remote start/stop for pump + basic safety interlocks
  - Display current state + last command result
  - Basic access control (operator vs admin)
- **Out of scope:**
  - Full role-based permissions matrix
  - Advanced analytics dashboards
  - Offline-first operation / store-and-forward control

##### Exit criteria (definition of done)
***Clear conditions for closing the Epic.***

Example:
- All planned **Feature sub-issues** are completed and accepted
- Critical docs updated (operator notes + user manual)
- Health checks and alerts added for the new control path
- Demo completed with a real robot + sign-off from ops/support

##### Epic Priority
***How urgently we need the outcome.***

Example:
- **Urgent**: blocks a customer delivery / safety issue / repeated incidents
- **High**: needed for next milestone
- **Normal**: valuable, but not time-critical
- **Low**: nice-to-have / opportunistic

##### Target window
***A rough delivery window (prefer ranges).***

Example:
- `Sprint 14â€“16`
- `Q1`
- `Before March field trials`

##### Dependencies / risks
***Anything that could block delivery or introduce uncertainty.***

Example:
- **Dependencies:**
  - API contract from telemetry service
  - Hardware availability for validation tests
  - Security review for remote control path
- **Risks:**
  - Unknown failure modes on poor connectivity
  - Safety interlocks need careful validation
  - Cross-repo coordination could slow integration
- **Mitigations (optional):**
  - Run a spike Feature to prototype comms behaviour
  - Add staged rollout + feature flag

---

#### Epic examples written as outcomes

**Remote operations MVP**
- Outcome: â€œAs a field operator, I can perform the core remote actions safely and verify they happened.â€
- Likely Features:
  - Operator can start/stop pump remotely (happy path)
  - Operator can view current state + last command result
  - Basic faults visible + clear error messages

**Telemetry pipeline v2**
- Outcome: â€œAs support/on-call, we can trust telemetry is captured, searchable, and exportable during incidents.â€
- Likely Features:
  - Export telemetry for time range
  - Buffering/retry when offline
  - Schema/versioning so fields donâ€™t silently break

**Reliability & watchdog improvements**
- Outcome: â€œThe system detects failures quickly and recovers automatically with clear diagnostics.â€
- Likely Features:
  - Service health endpoint + status page
  - Watchdog integration + restart policy
  - Alerting when telemetry stops / critical services restart

âœ… After creating the Epic, add it to the appropriate **Project** (right-hand sidebar â†’ **Projects**) and create the Features as **sub-issues** of the Epic.

---

<a id="feature"></a>
### ğŸ’¡ Feature

Use this when you want to describe a **chunk of added value** from a stakeholderâ€™s point of view â€” something someone can do afterwards that they couldnâ€™t do before (or can do more easily/safely). A Feature should be **small enough to complete within one sprint**.

A Feature should be written as a **user story** (who / what / why) with **user-facing acceptance criteria**. It is then broken down into **Tasks** (implementation steps). The stakeholder might be a customer/operator, but it can also be an internal stakeholder (e.g., a developer, support engineer, or operations).

#### Feature examples and field usage

Below are the same examples explaining what â€œgoodâ€ looks like for the fields specified.

---

#### Example 1: Emergency stop via RC transmitter

**Title**
- `ğŸ’¡ [FEATURE] - RC emergency stop to put bot in safe state`

**User story**
- As a **field operator**, I want to **stop all actuation of a bot using an RC transmitter**, so that I can **put the bot into a safe state**.

**Parent Epic**
- `#82` (Remote operations MVP)  
  *(or paste the full Epic URL if needed)*

**Acceptance criteria (user-facing, testable)**
- AC1: When the operator activates the RC e-stop, the bot enters **Safe State** within **â‰¤ 500 ms**.
- AC2: In Safe State, **all actuation outputs** are disabled (drive, pumps, valves, etc.) until explicitly cleared.
- AC3: The UI/telemetry exposes `safe_state = true` and a timestamp for the last e-stop event.
- AC4: If RC signal is lost for **> N ms**, the bot defaults to Safe State (fail-safe).
- AC5: A clear operator message is presented for Safe State entry and exit (no silent transitions).

**Notes / design / links**
- Context: Weâ€™ve had near-miss incidents during testing; need a fast, independent safety override.
- Approach:
  - Define Safe State semantics (what â€œactuation disabledâ€ means per subsystem).
  - RC receiver input â†’ debounced e-stop signal â†’ safety controller â†’ broadcast state.
- Links:
  - Safety requirements doc: â€¦
  - Firmware/IO mapping: â€¦
  - Related issues: #105 (RC receiver integration), #106 (telemetry field additions)

---

#### Example 2: Export telemetry for a time range

**Title**
- `ğŸ’¡ [FEATURE] - Export telemetry for a selected time range`

**User story**
- As a **support engineer**, I want to **export telemetry for a selected time range**, so that I can **diagnose incidents and share evidence quickly**.

**Parent Epic**
- `#140` (Telemetry pipeline v2)

**Acceptance criteria**
- AC1: Support can select a **start/end time** and export telemetry as **CSV** (minimum) via CLI or UI.
- AC2: Export includes **timestamps**, **unit-labelled fields**, and the **robot identifier**.
- AC3: Export completes within **â‰¤ 60 seconds** for a 1-hour window on a typical robot dataset (or provides progress indication).
- AC4: If data is missing, the export clearly indicates gaps (e.g., missing intervals, â€œno data availableâ€).
- AC5: Output is deterministic and shareable: same inputs â†’ same file content (ordering + formatting consistent).

**Notes / design / links**
- Context: Current investigations require manual log pulling and bespoke scripts.
- Approach:
  - Define export schema (columns + units).
  - Add filter-by-time query (DuckDB/SQLite/TSDB depending on stack).
  - Add a â€œshare bundleâ€ option later (out of scope for this Feature).
- Links:
  - Incident postmortem: â€¦
  - Telemetry schema repo/docs: â€¦
  - UX mock (if UI): â€¦

---

#### Example 3: Camera health status visibility

**Title**
- `ğŸ’¡ [FEATURE] - Display camera health status (online/FPS/last frame time)`

**User story**
- As an **operator**, I want to **see camera health status (online/offline, FPS, last frame time)**, so that I can **spot failures before they affect a mission**.

**Parent Epic**
- `#201` (Operational observability improvements)

**Acceptance criteria**
- AC1: Operator can view camera status: **Online/Offline**, **FPS**, and **Last frame received timestamp**.
- AC2: If no frame is received for **> 2 seconds**, status becomes **Degraded**; for **> 10 seconds**, **Offline**.
- AC3: Status updates at least every **5 seconds** without needing a manual refresh.
- AC4: Status is visible in both **local UI** and **remote UI** (if applicable) with the same semantics.
- AC5: A clear warning indicator is shown when status is Degraded/Offline (no hidden failures).

**Notes / design / links**
- Context: Operators often only notice camera failure after downstream perception breaks.
- Approach:
  - Source truth for â€œcamera aliveâ€ (frame timestamps from acquisition pipeline).
  - Define thresholds for degraded/offline.
  - Expose a single health endpoint + UI widget.
- Links:
  - Existing healthcheck endpoint: â€¦
  - Camera pipeline module docs: â€¦
  - Related bugs: #317 (sporadic FPS drops)

---

#### Example 4: Run full test suite in CI on every PR

**Title**
- `ğŸ’¡ [FEATURE] - Run full test suite in CI on every PR`

**User story**
- As a **developer**, I want to **run the full test suite in CI on every PR**, so that I can **catch regression issues before I merge**.

**Parent Epic**
- `#55` (Engineering effectiveness / build reliability)

**Acceptance criteria**
- AC1: On PR open/update, CI runs **build + unit tests** (minimum) and reports pass/fail in GitHub checks.
- AC2: CI finishes within **â‰¤ 20 minutes** for the standard PR path (or provides a fast/slow split).
- AC3: Failures provide actionable output (test name, logs/artifacts retained for â‰¥ 7 days).
- AC4: The main branch is protected so PRs require CI passing before merge (where appropriate).
- AC5: A developer can reproduce CI locally using documented instructions (dev container / script / make target).

**Notes / design / links**
- Context: Regressions are being found late; we need earlier feedback.
- Approach:
  - Add CI workflow(s): build matrix, caching, test execution.
  - Define minimum required checks and branch protection rules.
- Links:
  - CI proposal doc: â€¦
  - Existing workflow files: â€¦
  - Tooling: CMake presets / colcon config / test harness docs: â€¦

---

âœ… After creating the Feature, add it to the appropriate **Project** using the right-hand sidebar â†’ **Projects**.  
N.B. If you have linked the Feature to a Parent Epic that is already part of this project, the Feature should inherit this.

At Sprint Planning, once the issue is moved to **Ready**, please ensure that a **Priority** is assigned and an **Estimate** is given (using your team guide). If youâ€™re not sure which Project to use, email engineering@assetcool.com.

---

<a id="task"></a>
### ğŸ§© Task

Use a Task for a **small, concrete unit of implementation work** that supports a Feature. A Task should be something an engineer can pick up and complete in a short time (often hours to 1â€“2 days). Tasks are **engineering deliverables**, not stakeholder-facing outcomes.

Best practice: create Tasks as **sub-issues of a Feature** (use **Create sub-issue** from the Feature) so the hierarchy stays correct.

#### Typical Task examples
- Add a unit test for a module
- Implement a single API method
- Add logging/metrics to one component
- Refactor a function/class without changing behaviour
- Update a dependency and fix any fallout
- Write a small migration script/tool

---

#### Task template field examples

##### Linked Feature (required)
Paste the Feature this Task supports (issue number or full URL).

Examples:
- `#214`  
- `https://github.com/AssetCool/bot_system/issues/214`

Good rule: if you canâ€™t link it to a Feature, it might be a **Feature** (new value) or a **Bug** (something broken), not a Task.

##### Task goal (required)
One or two sentences: **what will be delivered**. Keep it specific and action-oriented.

Examples:
- â€œAdd a unit test covering CAN message parsing for pump start/stop commands.â€
- â€œImplement `GET /health/cameras` endpoint returning online/offline + last-frame timestamp.â€
- â€œRefactor `TelemetryPublisher` to separate serialization from transport (no behaviour change).â€

##### Verification / how to test (optional)
This is a â€œhow do I know this is done?â€ section. Keep it practical and reproducible.

Examples:
- â€œStart the stack locally, disconnect the camera, and confirm `/health/cameras` reports `offline` within 10s.â€
- â€œRun integration test `telemetry_export` and verify CSV contains timestamps + robot_id and the expected telemetry.â€

##### Implementation notes / links (optional)
Useful context for the implementer (approach, constraints, pointers). Keep it short.

Examples:
- â€œApproach: add parser tests using recorded CAN frames from `/var/logs/ac/can_samples/`.â€
- â€œDependency: requires Feature #214 schema to be merged first.â€
- â€œRelated PRs/issues: #301 (CAN heartbeat), PR #455 (healthcheck framework).â€

##### Definition of done
Use this checklist to avoid â€œalmost finishedâ€ tasks.

Suggested interpretation:
- **Work merged/commits made if part of a larger PR:** there is a PR merged, or the task is part of a larger PR and commits have been made and pushed.
- **Tests added/updated (if applicable):** if the change affects behaviour, add/adjust tests.
- **Docs updated (if applicable):** README/config docs updated if a user/operator/developer workflow changed.

---

#### Quick sizing guidance for Tasks
If a Task starts growing:
- If it needs multiple independent commits or several days of work â†’ split into **smaller Tasks**.
- If youâ€™re writing a new stakeholder-visible capability â†’ itâ€™s probably a **Feature**.
- If youâ€™re fixing something broken â†’ use **Bug Report** instead.

---

<a id="bug"></a>
### ğŸ› Bug Report

Use this when something is broken, unreliable, or behaving incorrectly in an existing system (i.e. not â€œnew workâ€, but a defect).

When you raise a bug, please fill in the template fields so someone else can reproduce and verify the fix:

- **Description:** whatâ€™s wrong, in one or two sentences.
- **Reproduction steps:** minimal steps to reliably trigger the problem.
- **Expected vs actual:** what should happen vs what does happen.
- **Environment / version:** device/OS/service version/commit/build (anything that might affect reproducibility).
- **Screenshots / Logs:** supporting evidence (error text, stack traces, photos, etc.).
- **Fix criteria:** how weâ€™ll know itâ€™s fixed (e.g., no longer repros; regression test added).

Examples:

**â€œPump start command returns â€˜OKâ€™, but the pump never starts.â€**
- Reproduction: send StartPump via UI â†’ observe no movement
- Expected: pump starts within 2s and state becomes Running
- Actual: state flips to Running but hardware remains off
- Env/version: Jetson Orin NX / Ubuntu 22.04 / bot_system vX.Y (commit â€¦)
- Logs: include CAN frames / controller logs

**â€œTelemetry drops out after ~10 minutes of running.â€**
- Reproduction: run system for 10â€“15 mins â†’ telemetry stream stops
- Expected: continuous telemetry at configured rate
- Actual: MQTT topic stops publishing; UI shows stale values
- Env/version: Jetson Orin NX / Ubuntu 22.04 / bot_system vX.Y (commit â€¦) / network type (Wi-Fi/LTE)
- Logs: MQTT client logs

**â€œClicking â€˜Save settingsâ€™ crashes the app.â€**
- Reproduction: open Settings â†’ change parameter â†’ click Save
- Expected: settings persist and success message shown
- Actual: app crashes / throws exception
- Evidence: screenshot/video + stack trace
- Fix criteria: add regression test; no crash; settings persist across restart

---

<a id="pull_request"></a>
### ğŸ” Pull Request (PR)

Use a PR to propose a change to the codebase that should be reviewed and merged. PRs are where we capture **what changed**, **why**, **how to verify it**, and **any rollout risk**.

This repository includes a PR template to make reviews consistent and fast. Below is guidance on how to fill it out with concrete examples.

---

#### What type of PR is this?
Tick all that apply. This helps reviewers quickly understand intent.

Examples:
- ğŸ• **Feature**: adds new capability  
  > â€œAdd `/health/cameras` endpointâ€
- ğŸ **Bug Fix**: fixes incorrect behaviour  
  > â€œFix CAN timeout parsing when frame length is 0â€
- ğŸ‘¨â€ğŸ’» **Refactor**: code restructure, no behaviour change  
  > â€œSplit TelemetryPublisher into serializer + transportâ€
- ğŸ”¥ **Performance Improvement**: measurably faster/leaner  
  > â€œReduce image pipeline allocations; improves FPS by ~15%â€
- ğŸ“ **Documentation Update**: docs-only change  
  > â€œUpdate user manual for watchdog restart behaviourâ€
- ğŸ” **CI**: workflows/build changes  
  > â€œEnable caching for colcon build in GitHub Actionsâ€
- ğŸ“¦ **Chore**: housekeeping  
  > â€œBump dependency versions; remove unused packageâ€
- âª **Revert**: revert a prior PR  
  > â€œRevert PR #456 due to regression in telemetry exportâ€

---

#### Description
Explain the change in plain English. Aim for:
- **What** you changed
- **Why** you changed it
- **What the user/system can do now**

Example:
> Adds a camera health endpoint and UI indicator so operators can see whether each camera is online and when the last frame was received. This reduces time-to-diagnose when perception fails due to camera dropout.

---

#### Related Tickets & Documents
Link issues and docs so the PR is traceable. Use GitHub keywords to auto-close issues on merge.

Examples:
- `Closes #214` (Feature issue)
- `Relates to #317` (bug, discussion, or follow-up)
- `Depends on #455` (blocked until another PR/issue merges)
- Links to design doc / spec / ADR:
  - â€œDesign notes: â€¦â€
  - â€œUser manual update: â€¦â€

Tip: If this PR implements a **Task**, also link that Task issue (and it should already be a sub-issue of the Feature).

---

#### Approach / Notes for reviewers
Help reviewers focus their attention. Call out:
- key design decisions
- trade-offs
- risky areas
- what you want reviewed most

Examples:
- â€œKey logic is in `CameraHealthService::computeStatus()` â€” please sanity check thresholds.â€
- â€œI chose polling over callbacks to keep acquisition pipeline unchanged.â€
- â€œMain risk: false offline detection on slow networks; thresholds are configurable.â€

---

#### How to test
This is the most important section for review quality. Be explicit.

Examples:
- **Unit:** `./build/unit_tests --gtest_filter=CameraHealth*`
- **Integration:** `./scripts/run_stack.sh` then `curl localhost:8080/health/cameras`
- **Manual:** unplug camera â†’ confirm UI shows **Degraded** in ~2s and **Offline** in ~10s

Good pattern:
- commands someone can copy/paste
- expected output or observable behaviour
- any test data needed and where to find it

---

#### Tests, Screenshots, Recordings
Attach evidence where it helps reviewers:
- screenshots of UI changes
- logs showing new behaviour
- short screen recording for workflows
- benchmark numbers for performance PRs

Example:
- â€œScreenshot: camera widget states (online/degraded/offline)â€
- â€œLog excerpt: health endpoint outputâ€
- â€œBefore/after FPS table (same dataset, same hardware)â€

---

#### Added/updated tests?
Be honest and specific.

Examples:
- ğŸ‘ **Yes**: â€œAdded unit tests for status threshold logic; updated integration test to assert endpoint schema.â€
- ğŸ™… **No, and this is why**: â€œPure documentation change.â€ / â€œSpike/prototype only; will add tests in follow-up Feature.â€
- ğŸ™‹ **I need help**: â€œNot sure how to mock the camera pipeline; suggestions welcome.â€
- âŒ **Not required**: â€œFormatting-only change; no behaviour impact.â€

---

#### Added to documentation?
Tick where you documented the change.

Examples:
- ğŸ“œ **README.md**: â€œNew env var `CAM_HEALTH_TIMEOUT_MS` and local test stepsâ€
- ğŸ¦† **In Code**: â€œAdded docstring + comments around thresholdsâ€
- ğŸ™ˆ **No Documentation Required**: only if truly internal/no user impact

---

#### Risk of rollout
This is for reviewers and release planning. Choose the highest plausible risk.

Examples:
- ğŸŸ¢ **Low**: refactor with no behaviour change + strong test coverage
- ğŸŸ  **Medium**: affects a shared module; may impact runtime behaviour; needs careful review
- ğŸ”´ **High**: touches safety/control paths, data loss risk, migration required, or hard-to-revert changes

If ğŸŸ /ğŸ”´, add a line in â€œApproach / Notesâ€ describing mitigation:
- feature flag
- staged rollout
- rollback plan
- additional monitoring

---

#### Post-merge tasks (optional)
Only check if thereâ€™s real follow-up work required **after** merge.

Examples:
- â€œDeploy to staging and verify telemetry export for 24 hoursâ€
- â€œUpdate Grafana dashboard to include new health metricsâ€
- â€œRun migration script on production databaseâ€

---

##### Review-friendly PR size guideline
Prefer PRs that can be reviewed in **15â€“30 minutes**. If itâ€™s too large:
- split into separate PRs (refactor â†’ feature â†’ cleanup)
- or split work into multiple Tasks/PRs under the same Feature

---

<a id="support"></a>
## ğŸ›Ÿ Support

If you need help with templates or youâ€™re unsure which issue type to use, contact the engineering team:

- Email: engineering@assetcool.com
